典型的 TinyML 模型壓縮和優化技術包括:

1. 量化(Quantization) 將模型權重和激活值從32位浮點數表示降低精度到8位或更低的定點數表示。這可以減少模型大小和運算量,同時保持準確率。
2. 剪枝(Pruning) 移除模型中不重要的神經元和聯繫。一種常見的剪枝方法是移除權重小的聯繫。這可以減少參數量而不大影響模型準確率。
3. 知識蒸餾(Knowledge Distillation) 使用教師模型(大型模型)對學生模型(小型模型)進行預訓練。這能讓小模型學會大模型的推理知識,提高小模型的表現。

這些方法通常聯合使用,從不同維度壓縮模型。例如先剪枝去掉不重要部分,再用蒸餾傳輸知識,最後量化降低參數精度。綜合應用可以使模型體積減小10倍以上。

# 關於剪枝，舉例示範

假設我們有一個簡單的神經網絡,包含輸入層、隱藏層和輸出層。我們可以這樣進行剪枝:

1. 訓練完成原始網絡後,檢查所有神經元之間的權重參數。假設設定一個閾值,權重參數絕對值小於這個閾值的聯繫就可被剪掉。
2. 去掉那些不重要的聯繫,得到一個剪枝後的網絡。這時我們再作一次訓練,讓剩下的參數進行調整適應,這個過程稱為微調。
3. 在验证集上評測剪枝後網絡的性能。跟原始模型的準確率對比,如果驗證準確率只下降很小(例如1%以內),那麼我們就可以接受這個剪枝模型。
4. 對比剪枝前後兩個模型在測試集上的表現。如果準確率基本一致,說明模型剪枝成功,實現了參數量的減少而性能基本維持。

在剪枝過程中,反覆評估和調整閾值非常重要。要平衡參數縮減量和準確率損失,達到最優的模型壓縮效果。

