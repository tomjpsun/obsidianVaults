[幫趣](https://bangqu.com/index.html)

# 網傳Ilya Sutskever的推薦清單火了，掌握當前AI 90%

 2024-05-09

隨著生成式 AI 模型掀起新一輪 AI 浪潮，越來越多的行業迎來技術變革。許多行業從業者、基礎科學研究者需要快速瞭解 AI 領域發展現狀、掌握必要的基礎知識。

如果有一份「機器學習精煉祕笈」，你認為應該涵蓋哪些知識？

近日，一份網傳 OpenAI 聯合創始人兼首席科學家 Ilya Sutskever 整理的一份機器學習研究文章清單火了。網友稱「Ilya 認為掌握了這些內容，你就瞭解了當前（人工智慧領域） 90% 的重要內容。」

![圖片](https://i3.res.bangqu.com/farm/j/news/2024/05/09/19d6bf5c916a72b438ef9d12efa1b39f.png)

推薦清單：https://arc.net/folder/D0472A20-9C20-4D3F-B145-D2865C0A9FEE

從研究主題上看，Ilya Sutskever 重點關注 transformer 架構、迴圈神經網路（RNN）、長短期記憶網路（LSTM）、神經網路的複雜度等。![圖片](https://i3.res.bangqu.com/farm/j/news/2024/05/09/1ea372e10b19ebb8f7eb347289fcd855.png)

                                                         _推薦清單部分截圖。_

例如，Ilya 推薦谷歌在 2017 年發表的經典論文《Attention Is All You Need》，這是 transformer 架構的問世之作。transformer 架構今天已經成為人工智慧領域的主流基礎架構，特別是它是生成式 AI 模型的核心架構。

Ilya 不僅推薦原論文，還推薦一篇由康奈爾大學副教授 Alexander Rush 等研究者在 2018 年撰寫的部落格文章 ——《The Annotated Transformer》。這篇文章以逐行實現的形式呈現了論文的註釋版本，它重新排序梳理了原論文的內容，並刪除了一些部分，最終展現的是一個完全可用的實現。2022 年 Austin Huang 等研究者又在其基礎上編輯整理出一份採用 PyTorch 實現的更新版部落格。

![圖片](https://i3.res.bangqu.com/farm/j/news/2024/05/09/e2aab9a6b919dd6c36b2db9654c9ae65.png)

在 RNN 方面，Ilya 首先推薦閱讀 AI 大牛 Andrej Karpathy2015 年撰寫的一篇部落格，強調「RNN 驚人的有效性」。

![圖片](https://i3.res.bangqu.com/farm/j/news/2024/05/09/b3422625ed6400c1848322c0f6410c04.png)

Ilya 還推薦了由紐約大學 Wojciech Zaremba（OpenAI創始團隊成員）和 Ilya Sutskever 本人 2015 年發表的論文《Recurrent Neural Network Regularization》。當時，Ilya 還是谷歌大腦的研究科學家。

![圖片](https://i3.res.bangqu.com/farm/j/news/2024/05/09/eb7454d650798d4f8e03c3a7af36cbdf.png)

這篇論文為 RNN 提出了一種簡單的正則化技術，闡述瞭如何正確地將 dropout 應用於 LSTM，大大減少了各種任務的過擬合，包括語言建模、語音識別、影象字幕生成、機器翻譯等等。

此外，Ilya 還推薦了 DeepMind、倫敦大學學院 2018 年聯合發表的論文《Relational recurrent neural networks》。

![圖片](https://i3.res.bangqu.com/farm/j/news/2024/05/09/a337c8b9b7552039f3b9b0eb60c7ded5.png)

在 LSTM 方面，Ilya 推薦了 Anthropic 聯合創始人、前 OpenAI 可解釋性團隊技術負責人 Christopher Olah 2015 年撰寫的部落格文章《Understanding LSTM Networks》，這篇文章全面細緻地講解了 LSTM 的基本知識，並闡明 RNN 取得的顯著成果本質上是依靠 LSTM 實現的。

![圖片](https://i3.res.bangqu.com/farm/j/news/2024/05/09/e2fbe135428e33cc4ddbecb1ad454ebd.png)

在「複雜度」方面，Ilya 重點推薦了《Kolmogorov Complexity and Algorithmic Randomness》一書中講解「演算法統計」的部分。柯爾莫哥洛夫複雜度為計算理論提供了一個用於探索問題固有複雜度的框架，可幫助研究人員更好地設計和評估 AI 模型。

![圖片](https://i3.res.bangqu.com/farm/j/news/2024/05/09/9b39b173f7908b67a67a125631719cd9.png)

在這份推薦清單中，我們還看到了一些著名 AI 學者的經典論文。例如，2012 年 ImageNet 影象識別大賽中圖靈獎得主 Geoffrey Hinton 組的論文《ImageNet Classification with Deep Convolutional Neural Networks》，這篇論文提出了 AlexNet，引入了全新的深層結構和 dropout 方法，顛覆了影象識別領域，甚至被認為開啟了深度學習革命。Ilya 也是這篇論文的三位作者之一。

![圖片](https://i3.res.bangqu.com/farm/j/news/2024/05/09/2c576eeadbceddfd16a4bdecd051e71c.png)

還有 2014 年，DeepMind Alex Graves 等人提出的神經圖靈機（NTM）。NTM 將神經網路的模糊模式匹配能力與可程式設計計算機的演算法能力相結合，具有 LSTM 網路控制器的 NTM 可以從輸入和輸出示例中推斷出簡單的演算法，例如複製，排序等。

![圖片](https://i3.res.bangqu.com/farm/j/news/2024/05/09/65c83211146ec2d4cc346bd850301b9c.png)

此外，Ilya 還推薦了神經網路應用於基礎科學（化學）的研究論文、擴充套件定律相關文章等等，並推薦了斯坦福大學電腦科學課程 CS231n：用於視覺識別的摺積神經網路。

![圖片](https://i3.res.bangqu.com/farm/j/news/2024/05/09/3662372a89c0a07d34ff5e8e26359869.png)

感興趣的讀者可以檢視原推薦清單，瞭解更多內容。

_參考連結：
https://twitter.com/keshavchan/status/1787861946173186062
文章來源：[機器之心](https://www.jiqizhixin.com/articles/2024-05-09-7)



清單上的27篇研究論文(或課程)如下：

1. The Annotated Transformer

![👉](https://static.xx.fbcdn.net/images/emoji.php/v9/t51/1/16/1f449.png)[https://lihi.cc/SYyu8](https://lihi.cc/SYyu8?fbclid=IwZXh0bgNhZW0CMTAAAR0iweTEDfjtRQ8BuiIM7KTsGdICRzpAV9D4FAQtkq37bMEHtl3zwuUi4t8_aem_AWWgHyf_Ji7sRCwtxThtDAssZgAt6e7O1Oom7IEz899VrHybOWzavtjsQb2bC6Sidr26qOY0_bDS7ncNanOpVFqd)

2. The First Law of Complexodynamics

![👉](https://static.xx.fbcdn.net/images/emoji.php/v9/t51/1/16/1f449.png)[https://lihi.cc/0vhEH](https://l.facebook.com/l.php?u=https%3A%2F%2Flihi.cc%2F0vhEH%3Ffbclid%3DIwZXh0bgNhZW0CMTAAAR2MyyM3IZJnSa20xfF8nhQHFeVizHs42y4kJghJCsj-4lJGmVBSJuZR4Iw_aem_AWWKFdhMwe5x_KWZXoiWhyMvJ5FJVp5Fyf98QAbVJWQs1liX56s7aiR4xmNb8g0vcMkFTSBFmcTy4p0XmklG4BXn&h=AT11v7CtQGsHXJ4lg29htFSABfH36VUD4h5MuQLDCZwXuXCfwaSlPAghhx7pYJERBiN8hWYsxi20Iz5ZWyIsa1oSaeIedKpYRIN7zYwF-Q70pVKZUczQ-6zcmbd8&__tn__=-UK-R&c[0]=AT2UL6wms0AOv-bfCq_3SkdJzHIYjHST4RlP3XoHJ09ZUR3Yd7Uwt2KhEr2LCj21WiJqwm_erAWgZRWBupqu_oQMTLcQM5_rR_027a9YpFoy1beWvlRW8SRcxNho4hBH-qRt9YrJs6FIS-881KycWHgPsdQAeOyu1Qn5A_qM1R8lZjWZbcJs0wKadnTO-ayVzhVToFHlx2_oUjlhN_UeDRAOcOmI9C7RlcMNfJY)

3. The Unreasonable Effectiveness of RNNs

![👉](https://static.xx.fbcdn.net/images/emoji.php/v9/t51/1/16/1f449.png)[https://lihi.cc/S9HSu](https://l.facebook.com/l.php?u=https%3A%2F%2Flihi.cc%2FS9HSu%3Ffbclid%3DIwZXh0bgNhZW0CMTAAAR1OPCGxCFrAfP_ZzyK5lGk7upVwaFszmCORyFmO_iDQwQfRdWyCAqec13U_aem_AWXOQ0ENDdzNDB19WKV_oLsNOuqMsqn-1Ddhl_rl-bkk58MRdYkvY644r0jq6iQJ5IVdU6Uc4HzYNF8SofKI0ITd&h=AT21CNOqBzSVsjSwJ48ZR4gbMWGkBYxuqiWwh7EW3tJQTPnnp4hpSKs4ywD54WzLpeEtduVJjrnUMz99PPl9J3RbTjfN23t1drTTjZAPXg8qUtLEVPNn5gHh-x6k&__tn__=-UK-R&c[0]=AT2UL6wms0AOv-bfCq_3SkdJzHIYjHST4RlP3XoHJ09ZUR3Yd7Uwt2KhEr2LCj21WiJqwm_erAWgZRWBupqu_oQMTLcQM5_rR_027a9YpFoy1beWvlRW8SRcxNho4hBH-qRt9YrJs6FIS-881KycWHgPsdQAeOyu1Qn5A_qM1R8lZjWZbcJs0wKadnTO-ayVzhVToFHlx2_oUjlhN_UeDRAOcOmI9C7RlcMNfJY)

4. Understanding LSTM Networks

![👉](https://static.xx.fbcdn.net/images/emoji.php/v9/t51/1/16/1f449.png)[https://lihi.cc/CLOpr](https://l.facebook.com/l.php?u=https%3A%2F%2Flihi.cc%2FCLOpr%3Ffbclid%3DIwZXh0bgNhZW0CMTAAAR2cRqq0xDk8MI7L1IbP95JTL-mJV45Jojp9YUOaFilCr5zUM8qxIIBXTRM_aem_AWWKF_N8y4cglYy9kxPjbMST4cUPnYaV6SW8CEb4BwO6Rph4URIg8NzTgab5Cu9aPB45-peLS8NbWS_RebmWiL-F&h=AT18EIDkcSSu7TZErLb2o14elIUwea0vIKeeVUOlO2k6RuQ7K1vzdBvXkqlMUr2GtSUMDWrt0GjVD-KaEqO9X8LcH2zlXTch3q-_79Yh2_IaUEh-EFIcACbRjktM&__tn__=-UK-R&c[0]=AT2UL6wms0AOv-bfCq_3SkdJzHIYjHST4RlP3XoHJ09ZUR3Yd7Uwt2KhEr2LCj21WiJqwm_erAWgZRWBupqu_oQMTLcQM5_rR_027a9YpFoy1beWvlRW8SRcxNho4hBH-qRt9YrJs6FIS-881KycWHgPsdQAeOyu1Qn5A_qM1R8lZjWZbcJs0wKadnTO-ayVzhVToFHlx2_oUjlhN_UeDRAOcOmI9C7RlcMNfJY)

5. Recurrent Neural Network Regularization

![👉](https://static.xx.fbcdn.net/images/emoji.php/v9/t51/1/16/1f449.png)[https://lihi.cc/vXW0C](https://l.facebook.com/l.php?u=https%3A%2F%2Flihi.cc%2FvXW0C%3Ffbclid%3DIwZXh0bgNhZW0CMTAAAR3PgiEZEzC6sWvIIP_hwSR4eIwGVNBbwJAP7i1ynHbV20Q-r6vsgj-Xjbo_aem_AWVJHHxOC45pDHs0TsQGL6lLS6fvNloWeyNVHa2mkeyIKYOYui2e08IDIIHM3xj0BQ1JcpB31E-iky5bFjqYHxoz&h=AT1kYuRPrjKrNsoW0D0V0pmoEU51EfN1PtFU1FIWYZxEyzIKlwZcl69Dh_nMICyMkhY5gfcTRsmTK1vJLzxfaGN8_m0sqMdTI7dWUvjN_-hnSsgeEoTN1mO14kbs&__tn__=-UK-R&c[0]=AT2UL6wms0AOv-bfCq_3SkdJzHIYjHST4RlP3XoHJ09ZUR3Yd7Uwt2KhEr2LCj21WiJqwm_erAWgZRWBupqu_oQMTLcQM5_rR_027a9YpFoy1beWvlRW8SRcxNho4hBH-qRt9YrJs6FIS-881KycWHgPsdQAeOyu1Qn5A_qM1R8lZjWZbcJs0wKadnTO-ayVzhVToFHlx2_oUjlhN_UeDRAOcOmI9C7RlcMNfJY)

6. Keeping Neural Networks Simple by Minimizing the Description Length of the Weights

![👉](https://static.xx.fbcdn.net/images/emoji.php/v9/t51/1/16/1f449.png)[https://lihi.cc/XDpbV](https://l.facebook.com/l.php?u=https%3A%2F%2Flihi.cc%2FXDpbV%3Ffbclid%3DIwZXh0bgNhZW0CMTAAAR3WZ4qErnc-BvE8Xk2mJerD_PUHpyPemxjsKZc-N_PI35WxirWHD0WNku8_aem_AWWalPi9qEgVIIXmJssUjLRqtswUvlCxu_81S7I28_gk5-vO2kciJrSIt97_d_qj2HQWXehE48m9iHwrF1y6pHXj&h=AT1mB7HvwRwu5h1EcuS3_7_9ODAwYNPzBjHdN23RmkDoQy6krS9t2ICBc4_LSIo2L6sNFOa3Bh9BvF35RphNYR3OPFuFvmpk_1RRWJ2pxtPFMr7-tzbpjAzlDOef&__tn__=-UK-R&c[0]=AT2UL6wms0AOv-bfCq_3SkdJzHIYjHST4RlP3XoHJ09ZUR3Yd7Uwt2KhEr2LCj21WiJqwm_erAWgZRWBupqu_oQMTLcQM5_rR_027a9YpFoy1beWvlRW8SRcxNho4hBH-qRt9YrJs6FIS-881KycWHgPsdQAeOyu1Qn5A_qM1R8lZjWZbcJs0wKadnTO-ayVzhVToFHlx2_oUjlhN_UeDRAOcOmI9C7RlcMNfJY)

7. Pointer Networks

![👉](https://static.xx.fbcdn.net/images/emoji.php/v9/t51/1/16/1f449.png)[https://lihi.cc/OifrR](https://l.facebook.com/l.php?u=https%3A%2F%2Flihi.cc%2FOifrR%3Ffbclid%3DIwZXh0bgNhZW0CMTAAAR3vtl039gPtzKIBJna0M2FFnTZD9fyar1lzrVN5Ml3z6JAhMe-zvVkK4S0_aem_AWUsu8y4B3qWbutft5RI76r0SMnLDyf2qXPrTZiqLMT8g--0HA9ENkN4mhZkSQXnIEUmgnds-idu5f-CChFsZ_c5&h=AT1KfjqWopNBHnXs9RCxEL0eJXzsOMJMco2KimZ8JiDfwAQO2CBRb4KT2Pzpr3ZeP6XqKyvibzoNcEfrWUM0blrzMUq91V9tI88KFyOZJjBN2lALG9H1GBpnlm4Y&__tn__=-UK-R&c[0]=AT2UL6wms0AOv-bfCq_3SkdJzHIYjHST4RlP3XoHJ09ZUR3Yd7Uwt2KhEr2LCj21WiJqwm_erAWgZRWBupqu_oQMTLcQM5_rR_027a9YpFoy1beWvlRW8SRcxNho4hBH-qRt9YrJs6FIS-881KycWHgPsdQAeOyu1Qn5A_qM1R8lZjWZbcJs0wKadnTO-ayVzhVToFHlx2_oUjlhN_UeDRAOcOmI9C7RlcMNfJY)

8. ImageNet Classification with Deep CNNs

![👉](https://static.xx.fbcdn.net/images/emoji.php/v9/t51/1/16/1f449.png)[https://lihi.cc/rXR7Y](https://l.facebook.com/l.php?u=https%3A%2F%2Flihi.cc%2FrXR7Y%3Ffbclid%3DIwZXh0bgNhZW0CMTAAAR3gE4bdRFQHzbQsl65YHTbe3efuuwsCuGoHv8nZ5QzZeHCWWgamu4FFYYA_aem_AWVH1fadm8QBEGsxFFtSnsmWZgr3knZ4bCzkkqFFNQfqt2IK4b4Mo37WrOJtmSrJgyWoJRnaZy2QMVuZkFYoBSX0&h=AT2_BR_bo6lx75SYhEngDuayHKQMGTof1iMKX5hXjBcul0nU60AeN3BZjq-OmbSfqQRuo6_3Q1Pjy6tJl4H64rwbJ_hy-QCyxNkqUnz0v4_0TEV2FfmKmr-uzPno&__tn__=-UK-R&c[0]=AT2UL6wms0AOv-bfCq_3SkdJzHIYjHST4RlP3XoHJ09ZUR3Yd7Uwt2KhEr2LCj21WiJqwm_erAWgZRWBupqu_oQMTLcQM5_rR_027a9YpFoy1beWvlRW8SRcxNho4hBH-qRt9YrJs6FIS-881KycWHgPsdQAeOyu1Qn5A_qM1R8lZjWZbcJs0wKadnTO-ayVzhVToFHlx2_oUjlhN_UeDRAOcOmI9C7RlcMNfJY)

9. Order Matters: Sequence to Sequence for Sets

![👉](https://static.xx.fbcdn.net/images/emoji.php/v9/t51/1/16/1f449.png)[https://lihi.cc/qew8w](https://l.facebook.com/l.php?u=https%3A%2F%2Flihi.cc%2Fqew8w%3Ffbclid%3DIwZXh0bgNhZW0CMTAAAR3WZ4qErnc-BvE8Xk2mJerD_PUHpyPemxjsKZc-N_PI35WxirWHD0WNku8_aem_AWWalPi9qEgVIIXmJssUjLRqtswUvlCxu_81S7I28_gk5-vO2kciJrSIt97_d_qj2HQWXehE48m9iHwrF1y6pHXj&h=AT1negcsFYb1-R36_yMduHpsqUREUilsFJVuKBnzrKy_AU-9xiRLBl-RAf4YM0H752O6Hk9Qu_ZnFhX_V3B73T2NIy-C4ddk0dh5q26j4sPqze2N9sy8DIWVzwHT&__tn__=-UK-R&c[0]=AT2UL6wms0AOv-bfCq_3SkdJzHIYjHST4RlP3XoHJ09ZUR3Yd7Uwt2KhEr2LCj21WiJqwm_erAWgZRWBupqu_oQMTLcQM5_rR_027a9YpFoy1beWvlRW8SRcxNho4hBH-qRt9YrJs6FIS-881KycWHgPsdQAeOyu1Qn5A_qM1R8lZjWZbcJs0wKadnTO-ayVzhVToFHlx2_oUjlhN_UeDRAOcOmI9C7RlcMNfJY)

10. GPipe: Efficient Training of Giant Neural Networks

![👉](https://static.xx.fbcdn.net/images/emoji.php/v9/t51/1/16/1f449.png)[https://lihi.cc/OprH8](https://lihi.cc/OprH8?fbclid=IwZXh0bgNhZW0CMTAAAR2YAzbzzjXayA7tdRY142GDppOTQCa4SvVVFeSRPUuFLnj9c1fpogyrG-E_aem_AWWcxEoog2PJRbyqcuRXmYcsf-iiyB3ajJHZSVv4zjzdH1Xun3QqV4QfSfEoTQnu1j_ADCEkBhAAoK2K1nawHI82)

11. Deep Residual Learning for Image Recognition

![👉](https://static.xx.fbcdn.net/images/emoji.php/v9/t51/1/16/1f449.png)[https://lihi.cc/TOzqG](https://lihi.cc/TOzqG?fbclid=IwZXh0bgNhZW0CMTAAAR30gAzuACb8hUn1--Dq7jLbRyYYjtuVF1vTseFKSPtv1UtB6H1QjwkACXc_aem_AWXNfAN4Lg2P1lrImODqJ2h966fmkz6PEtlfR9M_CPzxYU_2fT8Bpf9Pmhcjwm187eX3dapWWsEFsG68meJ7DT1T)

12. Multi-Scale Context Aggregation by Dilated Convolutions

![👉](https://static.xx.fbcdn.net/images/emoji.php/v9/t51/1/16/1f449.png)[https://lihi.cc/Q1Qfw](https://lihi.cc/Q1Qfw?fbclid=IwZXh0bgNhZW0CMTAAAR0bhwvlv_inhjZCh_jvPQe8t98Jx6Rmnsx0IFGmGQmGiizS-vgly71wvJo_aem_AWXzZlv4-1-pFEZcHd4CKQAPsVymkmgnGbJDoVUyUWLtqG1zADRmuHY7svM70qRYm-MwYMm0uhx0CoppObVMMTzl)

13. Neural Quantum Chemistry

![👉](https://static.xx.fbcdn.net/images/emoji.php/v9/t51/1/16/1f449.png)[https://lihi.cc/O03hP](https://lihi.cc/O03hP?fbclid=IwZXh0bgNhZW0CMTAAAR0bhwvlv_inhjZCh_jvPQe8t98Jx6Rmnsx0IFGmGQmGiizS-vgly71wvJo_aem_AWXzZlv4-1-pFEZcHd4CKQAPsVymkmgnGbJDoVUyUWLtqG1zADRmuHY7svM70qRYm-MwYMm0uhx0CoppObVMMTzl)

14. Attention Is All You Need

![👉](https://static.xx.fbcdn.net/images/emoji.php/v9/t51/1/16/1f449.png)[https://lihi.cc/8PbAX](https://lihi.cc/8PbAX?fbclid=IwZXh0bgNhZW0CMTAAAR1WHVL6xobWL9_5W7QyTxWCo_UV_nAZGj-DqbS4mvum3JJQGIwkF45c8Lw_aem_AWVfu8SLZTGaJFp7lHc2_AYxiI_zOzIOFz2l2pQ93U3u311kUC9JcutMg5eodz71sE1SnZml17h317U63wba2hXR)

15. Neural Machine Translation by Jointly Learning to Align and Translate

![👉](https://static.xx.fbcdn.net/images/emoji.php/v9/t51/1/16/1f449.png)[https://lihi.cc/jC8Ji](https://lihi.cc/jC8Ji?fbclid=IwZXh0bgNhZW0CMTAAAR2mJm6o28PfAVDLVUQw0_1y_xgoIjPctxrRej0zEHu_XUYGln46yBNFnhY_aem_AWW77QuixQ8xmZl1uHFktCNYQtI1Xtc60nOi9jULjEQW4J9_CidfCicsyOUMOcYdrleACf6T9DbFqMSwEAA5ktYn)

16. Identity Mappings in Deep Residual Networks

![👉](https://static.xx.fbcdn.net/images/emoji.php/v9/t51/1/16/1f449.png)[https://lihi.cc/qs7ia](https://lihi.cc/qs7ia?fbclid=IwZXh0bgNhZW0CMTAAAR3b48vyrmwsziijJOsIGl9Mj0OpYEnh2g9ehtd7CKhR2niQuc6YRT4voYw_aem_AWXqHa89rk3HXN0IUWiHyruSr0S58iddb5d9uUKjrHk9S1X5Gy-BZNd_6_urt_nsBVeCkDiXL1KlddDq7cS88SEm)

17. A Simple NN Module for Relational Reasoning

![👉](https://static.xx.fbcdn.net/images/emoji.php/v9/t51/1/16/1f449.png)[https://lihi.cc/swwv1](https://lihi.cc/swwv1?fbclid=IwZXh0bgNhZW0CMTAAAR2PxHBh84bWmB83x83bOa0_D48bwYjFCuY1B7cRrC6DyzqzRaLG0YLBBNg_aem_AWUN8YHJQcxkjQO8rwmzPFMzeZ2cv6LqXXvazj2a5uj-5JGykTo-Jgiid6tw-NzDm9Txfo29qyoEkQgNWsHAg0Q0)

18. Variational Lossy Autoencoder

![👉](https://static.xx.fbcdn.net/images/emoji.php/v9/t51/1/16/1f449.png)[https://lihi.cc/torVT](https://l.facebook.com/l.php?u=https%3A%2F%2Flihi.cc%2FtorVT%3Ffbclid%3DIwZXh0bgNhZW0CMTAAAR2mJm6o28PfAVDLVUQw0_1y_xgoIjPctxrRej0zEHu_XUYGln46yBNFnhY_aem_AWW77QuixQ8xmZl1uHFktCNYQtI1Xtc60nOi9jULjEQW4J9_CidfCicsyOUMOcYdrleACf6T9DbFqMSwEAA5ktYn&h=AT0XRCTUnuNkZWVVaT0Df0vPv_bMT3SY47gykFx2tInO2kauB8uMW7IEqZbYkyaGE7pD2bmYvEc5B_qGBYGVX3XDWk3AozneheIf6CDLvMq9iOJxiXmt4etT0TB6&__tn__=-UK-R&c[0]=AT2UL6wms0AOv-bfCq_3SkdJzHIYjHST4RlP3XoHJ09ZUR3Yd7Uwt2KhEr2LCj21WiJqwm_erAWgZRWBupqu_oQMTLcQM5_rR_027a9YpFoy1beWvlRW8SRcxNho4hBH-qRt9YrJs6FIS-881KycWHgPsdQAeOyu1Qn5A_qM1R8lZjWZbcJs0wKadnTO-ayVzhVToFHlx2_oUjlhN_UeDRAOcOmI9C7RlcMNfJY)

19. Relational RNNs

![👉](https://static.xx.fbcdn.net/images/emoji.php/v9/t51/1/16/1f449.png)[https://lihi.cc/3dqIM](https://l.facebook.com/l.php?u=https%3A%2F%2Flihi.cc%2F3dqIM%3Ffbclid%3DIwZXh0bgNhZW0CMTAAAR1_HQcyo51OC6XJPywPyI0ZQZ-0hQ0ygefVgGDJvYHhOJvUhZo-en7UnfE_aem_AWWzo6i4FFhecC9GXKk8rNdwzIvtQSecvt_ioVvVbhuCT9L17M-B0X285KU-C5a16goI-4LGkJXYYZyTzfs2q-ah&h=AT3GdVmuLGlVE0s4QgxlMoPxTTeCTRMpjhX3M5d9cpx7bt4Xyz259TwF5gF1qdkUHTi5QIHJ6qf1zgbJGii-SDMP5L4Ms8VCupqWOMARHKAbt4gMZqabEZ-zglM9&__tn__=-UK-R&c[0]=AT2UL6wms0AOv-bfCq_3SkdJzHIYjHST4RlP3XoHJ09ZUR3Yd7Uwt2KhEr2LCj21WiJqwm_erAWgZRWBupqu_oQMTLcQM5_rR_027a9YpFoy1beWvlRW8SRcxNho4hBH-qRt9YrJs6FIS-881KycWHgPsdQAeOyu1Qn5A_qM1R8lZjWZbcJs0wKadnTO-ayVzhVToFHlx2_oUjlhN_UeDRAOcOmI9C7RlcMNfJY)

20. Quantifying the Rise and Fall of Complexity in Closed Systems

![👉](https://static.xx.fbcdn.net/images/emoji.php/v9/t51/1/16/1f449.png)[https://lihi.cc/wCrY9](https://l.facebook.com/l.php?u=https%3A%2F%2Flihi.cc%2FwCrY9%3Ffbclid%3DIwZXh0bgNhZW0CMTAAAR3gE4bdRFQHzbQsl65YHTbe3efuuwsCuGoHv8nZ5QzZeHCWWgamu4FFYYA_aem_AWVH1fadm8QBEGsxFFtSnsmWZgr3knZ4bCzkkqFFNQfqt2IK4b4Mo37WrOJtmSrJgyWoJRnaZy2QMVuZkFYoBSX0&h=AT3taehtoNE5fVIznZOt4l5vyLAb09nqU7yM6n2Sz1eMNJb-TmXX9XzE8EI-R4brhg0CKK2t3hVVJ8t03qg_xRyi9o3_vFD6p4ZPSBW9qAj7hKG4L92YvE2so7h6&__tn__=-UK-R&c[0]=AT2UL6wms0AOv-bfCq_3SkdJzHIYjHST4RlP3XoHJ09ZUR3Yd7Uwt2KhEr2LCj21WiJqwm_erAWgZRWBupqu_oQMTLcQM5_rR_027a9YpFoy1beWvlRW8SRcxNho4hBH-qRt9YrJs6FIS-881KycWHgPsdQAeOyu1Qn5A_qM1R8lZjWZbcJs0wKadnTO-ayVzhVToFHlx2_oUjlhN_UeDRAOcOmI9C7RlcMNfJY)

21. Neural Turing Machines

![👉](https://static.xx.fbcdn.net/images/emoji.php/v9/t51/1/16/1f449.png)[https://lihi.cc/QYUlr](https://l.facebook.com/l.php?u=https%3A%2F%2Flihi.cc%2FQYUlr%3Ffbclid%3DIwZXh0bgNhZW0CMTAAAR30gAzuACb8hUn1--Dq7jLbRyYYjtuVF1vTseFKSPtv1UtB6H1QjwkACXc_aem_AWXNfAN4Lg2P1lrImODqJ2h966fmkz6PEtlfR9M_CPzxYU_2fT8Bpf9Pmhcjwm187eX3dapWWsEFsG68meJ7DT1T&h=AT28HSC328Mrh9DU5gKFOOI7Xm4cWjK60KOjogC2kp-nfG2gEZNAdSub5_lj_6Qz9zV2PXoq9FAqkFb_1e_FA-G2HRapBIU7-C6L-hZAZGPIroS-XKxRWVBPfWtt&__tn__=-UK-R&c[0]=AT2UL6wms0AOv-bfCq_3SkdJzHIYjHST4RlP3XoHJ09ZUR3Yd7Uwt2KhEr2LCj21WiJqwm_erAWgZRWBupqu_oQMTLcQM5_rR_027a9YpFoy1beWvlRW8SRcxNho4hBH-qRt9YrJs6FIS-881KycWHgPsdQAeOyu1Qn5A_qM1R8lZjWZbcJs0wKadnTO-ayVzhVToFHlx2_oUjlhN_UeDRAOcOmI9C7RlcMNfJY)

22. Deep Speech 2: End-to-End Speech Recognition in English and Mandarin

![👉](https://static.xx.fbcdn.net/images/emoji.php/v9/t51/1/16/1f449.png)[https://lihi.cc/NiVuu](https://l.facebook.com/l.php?u=https%3A%2F%2Flihi.cc%2FNiVuu%3Ffbclid%3DIwZXh0bgNhZW0CMTAAAR1_HQcyo51OC6XJPywPyI0ZQZ-0hQ0ygefVgGDJvYHhOJvUhZo-en7UnfE_aem_AWWzo6i4FFhecC9GXKk8rNdwzIvtQSecvt_ioVvVbhuCT9L17M-B0X285KU-C5a16goI-4LGkJXYYZyTzfs2q-ah&h=AT1IXmzKY2_6iJ8enDiKcGqhAbMEr3MyatWie3AF0wakqgQhvqBkRL1zLKVqIEPsmPmwizdW5lV_ZCnao__ULVAaZngjpSvQ-01u7c8aOdY1nNtB1PFAzepN0Hed&__tn__=-UK-R&c[0]=AT2UL6wms0AOv-bfCq_3SkdJzHIYjHST4RlP3XoHJ09ZUR3Yd7Uwt2KhEr2LCj21WiJqwm_erAWgZRWBupqu_oQMTLcQM5_rR_027a9YpFoy1beWvlRW8SRcxNho4hBH-qRt9YrJs6FIS-881KycWHgPsdQAeOyu1Qn5A_qM1R8lZjWZbcJs0wKadnTO-ayVzhVToFHlx2_oUjlhN_UeDRAOcOmI9C7RlcMNfJY)

23. Scaling Laws for Neural LMs

![👉](https://static.xx.fbcdn.net/images/emoji.php/v9/t51/1/16/1f449.png)[https://lihi.cc/vDlmu](https://lihi.cc/vDlmu?fbclid=IwZXh0bgNhZW0CMTAAAR3vsTqe5yZBiHylGOpxryDzWGIBi1gB-UpfHmorkM4j7QDvoiPkFlqtRmw_aem_AWXWxtCT1_dxvg-Kitj-Gsn3jkFCCbDUDPAyWKBEvfUJAbtnJzvDSLE34cDTrwWXs9JI9uR-Yqo_oQvxREwCC3X6)

24. A Tutorial Introduction to the Minimum Description Length Principle

![👉](https://static.xx.fbcdn.net/images/emoji.php/v9/t51/1/16/1f449.png)[https://lihi.cc/hssGb](https://lihi.cc/hssGb?fbclid=IwZXh0bgNhZW0CMTAAAR3vtl039gPtzKIBJna0M2FFnTZD9fyar1lzrVN5Ml3z6JAhMe-zvVkK4S0_aem_AWUsu8y4B3qWbutft5RI76r0SMnLDyf2qXPrTZiqLMT8g--0HA9ENkN4mhZkSQXnIEUmgnds-idu5f-CChFsZ_c5)

25. Machine Super Intelligence Dissertation

![👉](https://static.xx.fbcdn.net/images/emoji.php/v9/t51/1/16/1f449.png)[https://lihi.cc/S7PAn](https://lihi.cc/S7PAn?fbclid=IwZXh0bgNhZW0CMTAAAR1WHVL6xobWL9_5W7QyTxWCo_UV_nAZGj-DqbS4mvum3JJQGIwkF45c8Lw_aem_AWVfu8SLZTGaJFp7lHc2_AYxiI_zOzIOFz2l2pQ93U3u311kUC9JcutMg5eodz71sE1SnZml17h317U63wba2hXR)

26. PAGE 434 onwards: Komogrov Complexity

![👉](https://static.xx.fbcdn.net/images/emoji.php/v9/t51/1/16/1f449.png)[https://lihi.cc/PlZgV](https://l.facebook.com/l.php?u=https%3A%2F%2Flihi.cc%2FPlZgV%3Ffbclid%3DIwZXh0bgNhZW0CMTAAAR1bw7yJm0CmqQomWeHofVIzHWvr-6xNPQxLWujvy7lmESENV7B1Sp6MJCY_aem_AWVK8B8jNps6cHiZ0_Wz1AXeOSvHFrmHkrV0c60WJZxzlqkHYevSw2wMBqiHcW-z-VBHY7anwqP86cbdlMtqMsUg&h=AT2yGopN4lysoLL32_LfuPsy-cDbMC2jYa5k8ZveI_WfzJSyEOCF_gbA8nZak2KxC0U8YIwW5FagCPVcYpLJHnjt6B-H7I6TN4Kno38WqM-KoHoeUJi0Z71WT_MS&__tn__=-UK-R&c[0]=AT2UL6wms0AOv-bfCq_3SkdJzHIYjHST4RlP3XoHJ09ZUR3Yd7Uwt2KhEr2LCj21WiJqwm_erAWgZRWBupqu_oQMTLcQM5_rR_027a9YpFoy1beWvlRW8SRcxNho4hBH-qRt9YrJs6FIS-881KycWHgPsdQAeOyu1Qn5A_qM1R8lZjWZbcJs0wKadnTO-ayVzhVToFHlx2_oUjlhN_UeDRAOcOmI9C7RlcMNfJY)

27. CS231n Convolutional Neural Networks for Visual Recognition

![👉](https://static.xx.fbcdn.net/images/emoji.php/v9/t51/1/16/1f449.png)[https://lihi.cc/8uGQl](https://lihi.cc/8uGQl?fbclid=IwZXh0bgNhZW0CMTAAAR3vtl039gPtzKIBJna0M2FFnTZD9fyar1lzrVN5Ml3z6JAhMe-zvVkK4S0_aem_AWUsu8y4B3qWbutft5RI76r0SMnLDyf2qXPrTZiqLMT8g--0HA9ENkN4mhZkSQXnIEUmgnds-idu5f-CChFsZ_c5)

